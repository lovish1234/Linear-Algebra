{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that a linear equation cannot have two solutions. (Eigher one or infinitely many solutions) ??\n",
    "\n",
    "Think of the columns of $\\textbf{A}$ as the different directions we can travel to from origin, then determine how many different ways we can follow to reach $\\textbf{b}$.\n",
    "\n",
    "$$ \\textbf{A}\\textbf{x} = \\sum_{i}x_{i}\\textbf{A}_{:,i}$$\n",
    "\n",
    "If $\\textbf{b}$ is in the span of the coumns of $\\textbf{A}$, then $\\textbf{A}\\textbf{x}=\\textbf{b}$ must have  a solution. In this particular case, the span is called the range or **column space** of $\\textbf{A}$.\n",
    "\n",
    "The requirement that column space of $\\textbf{A}$ be all of $\\mathbb{R}^{m}$ implies that $\\textbf{A}$ must have atleast m columns. Otherwise dimensionalty of column space would be less than m. A an example take $\\textbf{A}$ as a $3 \\times 2$ matrix, that means we only have two $x_{i}$'s which can vary to produce the output. The output will lie on a 2-D plane in the 3-D space. However, this is necessary and not sufficient condition for $\\textbf{A}\\textbf{x}=\\textbf{b}$ having a solution.\n",
    "\n",
    "Even if the matrix has 3 columns, if two of them are the same, output for $\\textbf{A}\\textbf{x}$ would lie on $\\mathbb{R}^{2}$. Thus the columns should also be linearly independent.\n",
    "\n",
    "For the matrix $\\textbf{A}$ to have inverse, it is required that the equation has exactly one solution for each value of $\\textbf{b}$. Thus the matrix should have **m linearly independent columns**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Norm of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norms are the set of functions mapping vectros to a set of non-negative values. The norm of a vector $\\textbf{x}$ measures the distance between origin to the point x in the space.\n",
    "\n",
    "$$ ||\\textbf{x}||_{p} = \\Big(\\sum_{i}|x_{i}|^{p}\\Big)^{\\frac{1}{p}}$$\n",
    "\n",
    "Formally, norm us any function that satisfies the following properties :-\n",
    "\n",
    "- f(**x**)=0 $\\implies$ x=0\n",
    "- f(**x**+**y**) $\\leq$ f(**x**)+f(**y**) (triangle inequality)\n",
    "- $\\forall \\alpha \\in \\mathbb{R}$, f($\\alpha$**x**)=$\\alpha$f(**x**) \n",
    "\n",
    "Most common norm is the $L^{2}(\\textbf{x})$ norm, also denoted as $||\\textbf{x}||$. $L^{2}(\\textbf{x})$ norm grows very slowly near the origin, hence when we need the distance value to increase quickly near the origin we use $L^{1}(\\textbf{x})$ norm. This is very important for some problems in machine learning where we need to differnciate the elements which are exactly 0 with other which are near to 0. $L^{1}(\\textbf{x})$ norm grows at the same rate in all the locations. \n",
    "\n",
    "There are other commonly used norms defined as following :-\n",
    "\n",
    "- $L^{0}(\\textbf{x})$ norm - Number of non-zero elements in a vector $\\textbf{x}$. Actually this violates the third requirement of being a norm. Still, it is mis-named as a norm.\n",
    "- $L^{\\infty}(\\textbf{x})$ norm - Max element in the vector $\\textbf{x}$\n",
    "$$||\\textbf{x}||_{\\infty} = max_{i} |x_{i}| $$\n",
    "- Frobenius Norm - $L^{2}$ norm with a martix $\\textbf{A}$ instead of a vector $\\textbf{x}$\n",
    "$$ ||\\textbf{A}||_{2} = \\sqrt{\\Big(\\sum_{i}\\sum_{j}|A_{i,j}|^{2}\\Big)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Kind of Matrices \n",
    "\n",
    "#### Diagonal Matrices\n",
    "\n",
    "In Machine Learning, restricting some matrices to daigonal may result in a more efficient algorithm\n",
    "\n",
    "#### Symmetric Matrices \n",
    "\n",
    "#### Orthogonal Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be covered in this chapter \n",
    "\n",
    "- Eigendecomposition \n",
    "- Singular Value Decomposition\n",
    "- LU decomposition\n",
    "- QR decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
